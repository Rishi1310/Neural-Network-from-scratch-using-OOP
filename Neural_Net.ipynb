{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Neuron:\n",
    "    def __init__(self):\n",
    "        self.type = 'relu'\n",
    "        self.fp = 0\n",
    "        self.z = 0\n",
    "        self.W = []\n",
    "        self.b = 0\n",
    "        self.ac_1 = []\n",
    "        self.dz=0\n",
    "    \n",
    "    def _weighted_sum(self):\n",
    "        summ = 0\n",
    "        for i in range(len(self.ac_1)):\n",
    "            summ+=self.ac_1[i]*self.W[i]\n",
    "        return summ + self.b\n",
    "    \n",
    "    def _activation_fn(self):\n",
    "        if(self.type=='relu'):\n",
    "            if self.z > 0:\n",
    "                return self.z\n",
    "            return 0\n",
    "        elif(self.type=='sigm'):\n",
    "            return 1/(1+np.exp(-self.z))\n",
    "        else:\n",
    "            raise Exception('Invalid Activation Function')\n",
    "                    \n",
    "    def forward_propogate(self,inp,weights,bias,choice='relu'):\n",
    "        assert(len(inp)==len(weights))\n",
    "        self.type=choice\n",
    "        self.ac_1 = inp\n",
    "        self.W = weights\n",
    "        self.b = bias\n",
    "        self.z = self._weighted_sum()\n",
    "        self.fp = self._activation_fn()\n",
    "        return self.fp\n",
    "\n",
    "    def _back_activation_fn(self,dac):\n",
    "        if(self.type=='relu'):\n",
    "            if(self.z<0):\n",
    "                return 0\n",
    "            else:\n",
    "                return dac\n",
    "        elif(self.type=='sigm'):\n",
    "            return self.dac*self.fp*(1-self.fp)\n",
    "        else:\n",
    "            raise Exception(\"Invalid activation function\")\n",
    "\n",
    "    def back_propogate(self,dac):\n",
    "        self.dac = dac\n",
    "        self.dz = self._back_activation_fn(dac)\n",
    "        m = len(self.ac_1)\n",
    "        dw = np.array(self.ac_1)*self.dz\n",
    "        db = self.dz\n",
    "        dac_1 = np.array(self.W)*self.dz\n",
    "        return dw,db,dac_1\n",
    "\n",
    "class Layer:\n",
    "    def __init__(self, n_neurons):\n",
    "        self.neurons = []\n",
    "        self.n_neurons = n_neurons\n",
    "        for i in range(self.n_neurons):\n",
    "            self.neurons.append(Neuron())\n",
    "    \n",
    "    def forward_propogate(self, inputs, weights,bias,choice='relu'):\n",
    "        output = []\n",
    "        for i in range(self.n_neurons):\n",
    "            output.append(self.neurons[i].forward_propogate(inputs,weights[i],bias[i],choice))\n",
    "        return output\n",
    "    \n",
    "    def back_propogate(self,dacs):\n",
    "        dacs=np.array(dacs.mean(axis=0))\n",
    "        dws = []\n",
    "        dbs = []\n",
    "        dac_1s = []\n",
    "        for i in range(dacs.shape[0]):\n",
    "            temp1,temp2,temp3 = self.neurons[i].back_propogate(dacs[i])\n",
    "            dws.append(temp1)\n",
    "            dbs.append(temp2)\n",
    "            dac_1s.append(temp3)\n",
    "        return np.array(dws),np.array(dbs),np.array(dac_1s)\n",
    "    \n",
    "\n",
    "class Neural_Net:\n",
    "    def __init__(self, layers):\n",
    "        self.n_layers=len(layers)\n",
    "        self.inputs=None\n",
    "        self.outputs=None\n",
    "        self.Layers=[]\n",
    "        self.Weights=[]\n",
    "        self.WGrads = []\n",
    "        self.Bias=[]\n",
    "        self.BGrads = []\n",
    "        self.layers=layers\n",
    "        self.learning_rate = 0\n",
    "        self.n_inps = 0\n",
    "    \n",
    "    def _initialize(self):\n",
    "        for i in range(self.n_layers):\n",
    "            self.Layers.append(Layer(self.layers[i]))\n",
    "            if i==0:\n",
    "                self.Weights.append(np.random.randn(self.layers[i],len(self.inputs[0])))#####\n",
    "                self.Bias.append(np.random.randn(self.layers[0]))\n",
    "            else:\n",
    "                self.Weights.append(np.random.randn(self.layers[i],self.layers[i-1]))\n",
    "                self.Bias.append(np.random.randn(self.layers[i]))\n",
    "        self.Layers.append(Layer(1))\n",
    "        self.Weights.append(np.random.randn(1,self.layers[self.n_layers-1]))\n",
    "        self.Bias.append(np.random.randn(1))\n",
    "        \n",
    "        \n",
    "    def _showWandB(self):\n",
    "        print('Weights:',self.Weights)\n",
    "        print('Bias:',self.Bias)\n",
    "        \n",
    "    def _showGWandBG(self):\n",
    "        print('WGrads:',self.WGrads)\n",
    "        print('BGrads:',self.BGrads)\n",
    "        \n",
    "    def train(self,inps,outs,epochs=50,learning_rate = 0.03,printCost=False):\n",
    "        self.inputs = inps\n",
    "        self.outputs = outs\n",
    "        self.learning_rate = learning_rate\n",
    "        self._initialize()\n",
    "        cost_av = 0\n",
    "        cost_der_av = 0\n",
    "        self.n_inps = len(self.inputs)\n",
    "        WGtemp = []\n",
    "        BGtemp = []\n",
    "        print(self.predict([4,-2]))\n",
    "        for i in range(epochs):\n",
    "            if(printCost and i%50==0):\n",
    "                print(\"Epoch %d/%d\"%(i+1,epochs),end=\" \")\n",
    "#             self._showWandB()\n",
    "            for j in range(len(self.inputs)):\n",
    "                pred = self._forward_propogate(self.inputs[j])\n",
    "                cost,cost_der = self._compute_cost(pred,self.outputs[j])\n",
    "                WGtemp,BGtemp=self._back_propogate(cost_der)\n",
    "                cost_av+=cost\n",
    "                cost_der_av+=cost_der\n",
    "                if(j==0):\n",
    "                    self.WGrads = WGtemp\n",
    "                    self.BGrads = BGtemp\n",
    "                else:\n",
    "                    for k in range(len(self.Layers)):\n",
    "                        self.WGrads[k]=self.WGrads[k]+WGtemp[k]\n",
    "                        self.BGrads[k]=self.BGrads[k]+BGtemp[k]\n",
    "            for j in range(len(self.Layers)):\n",
    "                self.WGrads[j]=self.WGrads[j]/self.n_inps\n",
    "                self.BGrads[j]=self.BGrads[j]/self.n_inps\n",
    "            cost_av/=self.n_inps\n",
    "            cost_der_av/=self.n_inps\n",
    "            if(printCost and i%50==0):\n",
    "                print(\"Cost = %f, Cost_Der = %f\"%(cost_av,cost_der_av))\n",
    "#             self._showGWandBG()\n",
    "            self._update_weights()\n",
    "#         self._showWandB()\n",
    "#         self._showGWandBG()\n",
    "                \n",
    "    def _forward_propogate(self,temp):\n",
    "        for i in range(len(self.Layers)):\n",
    "            if i==0:\n",
    "                temp = self.Layers[i].forward_propogate(temp,self.Weights[i],self.Bias[i],'relu')\n",
    "            elif i==self.n_layers:\n",
    "                temp = self.Layers[i].forward_propogate(temp,self.Weights[i],self.Bias[i],choice='sigm')\n",
    "            else:\n",
    "                temp = self.Layers[i].forward_propogate(temp,self.Weights[i],self.Bias[i],'relu')\n",
    "        return temp\n",
    "    \n",
    "    def _compute_cost(self,pred,act,cost_type = 'crs_ent'):\n",
    "        temp_out = np.array(pred)\n",
    "        act=np.array(act)\n",
    "        act = np.expand_dims(act,axis=0)\n",
    "        m = act.shape[0]\n",
    "        if(cost_type == 'mse'):\n",
    "            cost = (1/(2*m))*(np.array(temp_out)-np.array(act))**2\n",
    "            cost_der = np.array(temp_out)-np.array(act)\n",
    "        elif(cost_type == 'crs_ent'):\n",
    "            cost = (-1 / m) * (np.multiply(act, np.log(temp_out)) + np.multiply(1 - act, np.log(1 - temp_out)))\n",
    "            cost_der =  (-1/m)* (np.divide(act, temp_out) - np.divide(1 - act, 1 - temp_out))\n",
    "        else:\n",
    "            raise Exception('Invalid cost function given.')\n",
    "        return cost,cost_der\n",
    "    \n",
    "    def _back_propogate(self,cost_der):\n",
    "        temp3 = np.array(cost_der)\n",
    "        temp3 = np.expand_dims(temp3,axis=1)\n",
    "        Wg = []\n",
    "        Bg = []\n",
    "        for i in reversed(range(len(self.Layers))):\n",
    "            temp1, temp2, temp3 = self.Layers[i].back_propogate(temp3)\n",
    "            Wg.insert(0,temp1)\n",
    "            Bg.insert(0,temp2)\n",
    "        return Wg,Bg\n",
    "            \n",
    "    def _update_weights(self):\n",
    "        for i in range(len(self.Layers)):\n",
    "            self.Weights[i] = self.Weights[i] - self.learning_rate * self.WGrads[i]\n",
    "            self.Bias[i] = self.Bias[i] - self.learning_rate * self.BGrads[i]\n",
    "            \n",
    "    def predict(self,p):\n",
    "        temp = p\n",
    "        for i in range(len(self.Layers)):\n",
    "            if i==0:\n",
    "                temp = self.Layers[i].forward_propogate(temp,self.Weights[i],self.Bias[i],'relu')\n",
    "            elif i==self.n_layers:\n",
    "                temp = self.Layers[i].forward_propogate(temp,self.Weights[i],self.Bias[i],choice='sigm')\n",
    "            else:\n",
    "                temp = self.Layers[i].forward_propogate(temp,self.Weights[i],self.Bias[i],'relu')\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40769741424634703]\n",
      "Epoch 1/300 Cost = 0.873116, Cost_Der = -1.545374\n",
      "Epoch 51/300 Cost = 0.376985, Cost_Der = 0.080946\n",
      "Epoch 101/300 Cost = 0.184066, Cost_Der = 0.007893\n",
      "Epoch 151/300 Cost = 0.073285, Cost_Der = -0.038534\n",
      "Epoch 201/300 Cost = 0.047335, Cost_Der = -0.027056\n",
      "Epoch 251/300 Cost = 0.035321, Cost_Der = -0.022253\n",
      "[0.9642939678717656]\n",
      "[0.031334216146563884]\n",
      "[0.004159636600556321]\n",
      "[0.9642939678717656]\n",
      "[0.9642939678717656]\n",
      "[0.00019616054247881105]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "net = Neural_Net([3,4])\n",
    "inputs = [[-4,-2],[2,3],[1,1],[-6,-6],[4,5],[7,-10]]\n",
    "outputs = [1,0,0,1,1,0]\n",
    "\n",
    "net.train(inputs,outputs,epochs=300,learning_rate=0.3,printCost = True)\n",
    "print(net.predict([-4,-2]))\n",
    "print(net.predict([2,3]))\n",
    "print(net.predict([1,1]))\n",
    "print(net.predict([-6,-6]))\n",
    "print(net.predict([4,5]))\n",
    "print(net.predict([7,-10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
